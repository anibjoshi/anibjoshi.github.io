# CPUs vs GPUs: What I learned building my AI rig

Deep Learning is an intense computational process. After spending a lot of money on Azure and AWS VM instances for training deep learning models, I finally bit the bullet and decided to build a deep learning computer at home. This turned out to be a fun and rewarding experience that taught me a lot about how AI hardware actually works, why GPUs matter in training neural networks, and how to make the right tradeoffs while building a rig that's right for your use cases.
This post is my effort at explaining what I've learned.

## Experience building the rig

Back in April 2023, Elon Musk tweeted "Everyone and their dog is buying GPUs". Indeed if you go around looking for GPUs that have enough juice to train LLMs or other forms of generative models, you would be shocked at the premium you would have to pay. For example, an NVidia H100 GPU that retails at $25,000-$30,000 would set you back nearly $50,000 (with a 2 month lead time). On the enthusiast side of the market, things are even worse. An NVidia 4090, which is the best consumer GPU right now, retails at $1599 but has not been seen at that price since launch day.
So when I set out to build my AI rig, I realized I was looking at plunking down thousands of dollars of markup to scalpers if I wanted the top-of-the-line GPU. No can do.

What I needed was a lower tier GPU that would be powerful enough to let me get started and build train decently large models, along with a CPU/motherboard combo that could support a more powerful GPU if and when I decide to buy one. This meant reading technical blogs and watching (excellent) videos on computer hardware to understand how to make the right choices. It also meant understanding how neural networks train at the hardware level. Fun.

(I'll describe my eventual selections and reasoning at the end of the post.)

## How do GPUs work and why do they perform so well in neural network training?